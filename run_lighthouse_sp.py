import subprocess
import os
import json
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import Alignment, Border, Side
from openpyxl.utils import get_column_letter
from datetime import datetime

# è¨ˆæ¸¬ã™ã‚‹URLãƒªã‚¹ãƒˆ
urls = [
    "https://furusato.jreast.co.jp/furusato",  # URL A
    "https://furusato.jreast.co.jp/furusato/ranking"   # URL B
]

# Lighthouseã®è¨ˆæ¸¬ã¨Excelã¸ã®ä¿å­˜ã‚’è¡Œã†é–¢æ•°
def run_lighthouse_for_url(url, output_dir):
    os.makedirs(output_dir, exist_ok=True)  # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ

    # Lighthouseã®ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š
    for i in range(1, 6):  # 5å›è¨ˆæ¸¬
        output_path_json = os.path.abspath(os.path.join(output_dir, f"report_{i}.json"))
        log_path = os.path.abspath(os.path.join(output_dir, f"lighthouse_verbose_run_{i}.log"))

        print(f"Running Lighthouse for run {i} on URL: {url}")
        print(f"Output JSON path: {output_path_json}")
        print(f"Log path: {log_path}")

        # Lighthouseã‚’å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰
        command_json = [
            "npx", "lighthouse", url,
            "--preset=perf",
            "--output", "json", "html",
            "--output-path", output_path_json,
            "--chrome-flags=\"--headless --no-sandbox\"",
            "--max-wait-for-load=60000",
            "--verbose",
            "--emulated-form-factor=mobile",
            "--throttling-method=simulate",
            "--throttling.cpuSlowdownMultiplier=2",
            "--throttling.throughputKbps=6000",
            "--throttling.uploadThroughputKbps=750",
            "--throttling.latency=100"
        ]
        with open(log_path, "w") as log_file:
            result_json = subprocess.run(command_json, stdout=log_file, stderr=subprocess.STDOUT)

        if result_json.returncode == 0:
            print(f"Lighthouse JSON run {i} completed successfully.")
        else:
            print(f"Error in Lighthouse JSON run {i}. Check {log_path} for details.")
            break

    # æŒ‡æ¨™ã®æŠ½å‡ºã¨Excelä¿å­˜
    save_metrics_to_excel(output_dir, url)

def save_metrics_to_excel(output_dir, url):
    metrics_to_extract = [
        "FCP(ms)",
        "LCP(ms)",
        "CLS",
        "Speed Index(ms)",
        "TBT(ms)",
        "TTI(ms)",
        "TTFB(ms)",
        "Performance"
    ]

    results = []
    for i in range(1, 6):  # JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒ5ã¤ã‚ã‚‹ã¨ä»®å®š
        json_path = os.path.join(output_dir, f"report_{i}.json")
        if os.path.exists(json_path):
            with open(json_path, 'r') as f:
                data = json.load(f)
                try:
                    audits = data.get("audits", {})
                    performance_score = data.get("categories", {}).get("performance", {}).get("score", "N/A")
                    result = {
                        "run": i,
                        "Performance": round(performance_score * 100, 2) if isinstance(performance_score, (int, float)) else "N/A",
                        "TTFB(ms)": audits.get("server-response-time", {}).get("numericValue", "N/A"),
                        "FCP(ms)": audits.get("first-contentful-paint", {}).get("numericValue", "N/A"),
                        "LCP(ms)": audits.get("largest-contentful-paint", {}).get("numericValue", "N/A"),
                        "Speed Index(ms)": audits.get("speed-index", {}).get("numericValue", "N/A"),
                        "TBT(ms)": audits.get("total-blocking-time", {}).get("numericValue", audits.get("total-blocking-time", {}).get("errorMessage", "N/A")),
                        "TTI(ms)": audits.get("interactive", {}).get("numericValue", audits.get("interactive", {}).get("errorMessage", "N/A")),
                        "CLS": audits.get("cumulative-layout-shift", {}).get("numericValue", "N/A")
                    }
                    results.append(result)
                except KeyError as e:
                    print(f"Error extracting metrics from {json_path}: {e}")
        else:
            print(f"JSON file {json_path} not found!")

    # DataFrameã‚’ä½œæˆ
    if results:
        df = pd.DataFrame(results)

        # å¹³å‡å€¤ã‚’è¨ˆç®—
        averages = pd.DataFrame([df.mean(numeric_only=True)]).assign(run="average")
        df = pd.concat([df, averages], ignore_index=True)

        # å®Ÿè¡Œå®Œäº†æ—¥æ™‚ã‚’å–å¾—
        completed_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®æ›¸ãå‡ºã—
        excel_path = os.path.join(output_dir, f"{output_dir}.xlsx")
        with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
            # ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
            df.to_excel(writer, index=False, startrow=2, sheet_name="Metrics")  # 2è¡Œç›®ã‹ã‚‰æ›¸ãå§‹ã‚ã‚‹
            workbook = writer.book
            worksheet = writer.sheets["Metrics"]

            # URLã¨å®Ÿè¡Œæ—¥æ™‚ã‚’è¿½åŠ 
            worksheet["A1"] = f"URL: {url}"
            worksheet["A2"] = f"Completed at: {completed_datetime}"

            # åˆ—å¹…ã®èª¿æ•´
            for col_num in range(2, 9):  # Bã€œH
                col_letter = get_column_letter(col_num)
                worksheet.column_dimensions[col_letter].width = 15

            # æ ç·šã‚’è¨­å®š
            thin_border = Border(
                left=Side(style="thin"),
                right=Side(style="thin"),
                top=Side(style="thin"),
                bottom=Side(style="thin"),
            )
            for row in worksheet.iter_rows():
                for cell in row:
                    if cell.row > 2:  # ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã«æ ç·šã‚’è¨­å®š
                        cell.border = thin_border

            # å·¦æƒãˆã®è¨­å®šï¼ˆAåˆ—ã¨1è¡Œç›®ï¼‰
            for cell in worksheet["A"]:
                cell.alignment = Alignment(horizontal="left")

        print(f"è¨ˆæ¸¬çµæœã®Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¬¡ã®å ´æ‰€ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸğŸ’«: {excel_path}")
    else:
        print("No metrics data found. Excel file not created.")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    for url in urls:
        # URLã”ã¨ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        output_dir = url.split("//")[1].replace("/", "_")  # URLã‚’å®‰å…¨ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã«å¤‰æ›
        run_lighthouse_for_url(url, output_dir)
